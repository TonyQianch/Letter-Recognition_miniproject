{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import os\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conver image to csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using data from NIST dataset. The problem of this data set is the the images have 128 x 128 pixels, which may cause intensive computation. By convention, we need to resize the images to 28 x 28 pixels. Here we use the conversion process described in this paper(https://arxiv.org/pdf/1702.05373v1.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just resize the original image to 28 x 28 directly\n",
    "\n",
    "def simple_convert(img):\n",
    "    fig, axs = plt.subplots(1,2)\n",
    "    axs[0].imshow(img, cmap='gray_r')\n",
    "    axs[0].set_title('original imgage')\n",
    "    img = cv2.resize(img,(28,28),interpolation = cv2.INTER_CUBIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample_image = np.uint8(sample_image)\n",
    "def convert(img,size):\n",
    "    # eg: size = (28,28)\n",
    "    blur = cv2.GaussianBlur(img, (5,5),1)\n",
    "    ret, thresh = cv2.threshold(blur, 127, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    \n",
    "    contours= cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    ctrs = contours[1]\n",
    "    if len(ctrs) ==1:\n",
    "        img = cv2.resize(blur, size, interpolation = cv2.INTER_CUBIC)\n",
    "        return img\n",
    "    else:\n",
    "        x,y,w,h = (0,0,0,0)\n",
    "        for ctr in ctrs:\n",
    "            x_,y_,w_,h_ = cv2.boundingRect(ctr)\n",
    "            if w_*h_ == 128*128:\n",
    "                pass\n",
    "            elif w_*h_ > w*h:\n",
    "                x,y,w,h = x_,y_,w_,h_\n",
    "\n",
    "        img = blur[y:y+h,x:x+w]\n",
    "        img = cv2.copyMakeBorder(img,2,2,2,2,cv2.BORDER_CONSTANT, value = 255)\n",
    "\n",
    "        img = cv2.resize(img, size, interpolation = cv2.INTER_CUBIC)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now write the images to csv\n",
    "\n",
    "letters = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'\n",
    "labels = [i for i in range(52)]\n",
    "letter_code = [str(i) for i in range(41,50)]+['4a','4b','4c','4d','4d','4f']+[str(i) for i in range(50,60)] + ['5a']\n",
    "letter_code = letter_code+[str(i) for i in range(61,70)]+['6a','6b','6c','6d','6d','6f']+[str(i) for i in range(70, 80)] + ['7a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../EMNIST_28_28_v2.csv','w',newline = '') as f:\n",
    "    column_name = ['label']\n",
    "    column_name.extend(['pixel%d'%i for i in range(28*28)])\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(column_name)\n",
    "    for i in labels:\n",
    "        path = '/Users/taotao/Downloads/by_class/'+letter_code[i]+'/train_'+letter_code[i]\n",
    "        for img_path in sorted(os.listdir(path)):\n",
    "            img = cv2.imread(os.path.join(path,img_path),0)\n",
    "            img_converted = convert(img,(28,28))\n",
    "            row_data = [i]\n",
    "            print('label = {}'.format(img_path),end = '\\r')\n",
    "            row_data.extend(img_converted.flatten())\n",
    "            writer.writerow(row_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation,Conv2D\n",
    "from keras.layers import MaxPool2D,Flatten,Dropout,ZeroPadding2D,BatchNormalization\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use external code here, from website https://www.kaggle.com/grfiv4/plot-a-confusion-matrix\n",
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "    \"\"\"\n",
    "    given a sklearn confusion matrix (cm), make a nice plot\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    "\n",
    "    target_names: given classification classes such as [0, 1, 2]\n",
    "                  the class names, for example: ['high', 'medium', 'low']\n",
    "\n",
    "    title:        the text to display at the top of the matrix\n",
    "\n",
    "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                  plt.get_cmap('jet') or plt.cm.Blues\n",
    "\n",
    "    normalize:    If False, plot the raw numbers\n",
    "                  If True, plot the proportions\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
    "                                                              # sklearn.metrics.confusion_matrix\n",
    "                          normalize    = True,                # show proportions\n",
    "                          target_names = y_labels_vals,       # list of names of the classes\n",
    "                          title        = best_estimator_name) # title of graph\n",
    "\n",
    "    Citiation\n",
    "    ---------\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "    \"\"\"\n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(15, 12))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code is from Bibliography[10]\n",
    "#do one hot encoding for labels\n",
    "#aka if original label is 3\n",
    "#after one-hot, it becomes a 26-long array\n",
    "#[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]  \n",
    "def one_hot(labels):\n",
    "    num_labels=labels.shape[0]\n",
    "    result=np.zeros((num_labels,26))\n",
    "    offset=np.arange(num_labels)*26\n",
    "    result.flat[offset+labels.ravel()]=1\n",
    "    return result  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part, we create a simple NN model which serve as baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading and preprocessing dataset\n",
    "alphabet = pd.read_csv('../EMNIST_28_28_v2.csv')\n",
    "#split features and labels\n",
    "images=alphabet.iloc[:,1:].values\n",
    "raw_labels=alphabet.iloc[:,0].values.ravel()\n",
    "\n",
    "print('The dimensions of features are',images.shape)\n",
    "print('The dimensions of raw labels are',raw_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=one_hot(raw_labels-1)\n",
    "images=images.reshape(images.shape[0],28,28,1).astype(\"float32\")\n",
    "images=images/255\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(images, labels, test_size = 0.3)\n",
    "y = np.array([j for i in Y_test for j in range(len(i)) if i[j] != 0.0])\n",
    "letters = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'#label for plots in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = Sequential()\n",
    "baseline.add(Flatten())\n",
    "baseline.add(Dense(512,activation='relu'))\n",
    "baseline.add(Dropout(0.2))\n",
    "baseline.add(Dense(26,activation='softmax'))\n",
    "baseline.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting baseline model\n",
    "baseline.fit(x=X_train,y=Y_train,batch_size=300,epochs=50,verbose=1,validation_split=0.2)\n",
    "baseValLoss = baseline.history.history['val_loss']\n",
    "baseValAcc = baseline.history.history['val_acc']\n",
    "baseAcc = baseline.history.history['acc']\n",
    "baseLoss = baseline.history.history['loss']\n",
    "epoch = baseline.history.epoch\n",
    "plt.plot(epoch,baseAcc,'b',label = 'train_acc')\n",
    "plt.plot(epoch,baseValAcc,'bo',label = 'val_acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('Baseline Model')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.plot(epoch,baseLoss,'r',label = 'train_loss')\n",
    "plt.plot(epoch,baseValLoss,'ro',label = 'val_loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.title('Baseline Model')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epoch,baseAcc,'b',label = 'train_acc')\n",
    "plt.plot(epoch,baseValAcc,'bo',label = 'val_acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('Baseline Model')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.plot(epoch,baseLoss,'r',label = 'train_loss')\n",
    "plt.plot(epoch,baseValLoss,'ro',label = 'val_loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.title('Baseline Model')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction performance of the baseline model\n",
    "yPredBase = np.array([np.argmax(i) for i in baseline.predict(X_test)])\n",
    "confusion = confusion_matrix(y, yPredBase, labels=[i for i in range(26)]) \n",
    "plot_confusion_matrix(cm=confusion,normalize=False,target_names=[i for i in letters])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part, we use csv file to train using CNN\n",
    "\n",
    "As mentioned in report, the basic architecture of CNN build by Keras is following this tutorial: \n",
    "https://machinelearningmastery.com/handwritten-digit-recognition-using-convolutional-neural-networks-python-keras/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data from csv file\n",
    "alphabet = pd.read_csv('../EMNIST_28_28_v2.csv')\n",
    "#shuffle the data set\n",
    "alphabet=alphabet.sample(frac=1)\n",
    "#split features and labels\n",
    "images=alphabet.iloc[:,1:].values\n",
    "raw_labels=alphabet.iloc[:,0].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=one_hot(raw_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images=images.reshape(images.shape[0],28,28,1).astype(\"float32\")\n",
    "images=images/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built the model\n",
    "cnn = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following layers is a modified code from reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Layer-1\n",
    "#Basic Convolutional layer and ReLU Layer===========\n",
    "#ReLU is an activation layer, we do it after every Convolutional layer.\n",
    "#How it works?  If input is x, then output is  max(0, x)\n",
    "cnn.add(Conv2D(64,kernel_size=(3,3),strides=(1,1),input_shape=(28,28,1), activation='relu'))\n",
    "cnn.add(Conv2D(64,kernel_size=(3,3),activation='relu'))\n",
    "#Normalization Layer=========\n",
    "cnn.add(BatchNormalization(epsilon=1e-6,axis=1))\n",
    "#Pooling Layer==========\n",
    "#Reduce number of parameters and prevent OVERFITTING,usually the pool size is (2,2)\n",
    "#MaxPool means, if we have a 2*2 block, we choose the biggest number \n",
    "#  4  5\n",
    "#  8  1\n",
    "#Then after MaxPool, the output is 8, a 1*1 block.\n",
    "cnn.add(MaxPool2D(pool_size=(2,2)))\n",
    "cnn.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Layer-2\n",
    "#Padding Layer===========\n",
    "#Since each time we use Convolutional layer, the input size would become smaller,\n",
    "#so we add a Padding, here we set it to (1,1),\n",
    "#which means if input size is H*W, after this layer, it would become (H+1)*(W+1)\n",
    "cnn.add(Conv2D(64,kernel_size=(3,3),padding='same',activation='relu'))\n",
    "\n",
    "#Basic Convolutional layer and ReLU Layer===========\n",
    "cnn.add(Conv2D(64,kernel_size=(3,3),activation='relu'))\n",
    "#Normalization Layer=========\n",
    "cnn.add(BatchNormalization(epsilon=1e-6,axis=1))\n",
    "#Pooling Layer==========\n",
    "cnn.add(MaxPool2D(pool_size=(2,2)))\n",
    "cnn.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Layer-3\n",
    "#Padding Layer===========\n",
    "cnn.add(Conv2D(64,kernel_size=(3,3),padding='same',activation='relu'))\n",
    "#Basic Convolutional layer and ReLU Layer===========\n",
    "cnn.add(Conv2D(64,kernel_size=(3,3),activation='relu'))\n",
    "#Normalization Layer=========\n",
    "cnn.add(BatchNormalization(epsilon=1e-6,axis=1))\n",
    "#Pooling Layer==========\n",
    "cnn.add(MaxPool2D(pool_size=(2,2)))\n",
    "cnn.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fully Connected Layer --- aka Last Layer\n",
    "#Dropout Layer===========\n",
    "#This should always be in the last layer\n",
    "#It randomly drops out some parameter, still it prevents OVERFITTING.\n",
    "cnn.add(Dropout(0.25))\n",
    "cnn.add(Flatten())\n",
    "\n",
    "#Dense Layer==========\n",
    "#Its job is to do classification\n",
    "cnn.add(Dense(512, activation='relu'))\n",
    "cnn.add(Dense(26, activation='softmax'))\n",
    "\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the model and save check point\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "checkpoint=ModelCheckpoint(filepath=\"best_weights.hdf5\",monitor='val_acc',save_best_only=True)\n",
    "\n",
    "# Train and Predict\n",
    "#Epoch means the times you want to train,here I just set epoch=1, since one round takes about 30 mins.\n",
    "#validation_split, I split 80% as training data, 20% as test data\n",
    "#verbose=1 means print the log, =0 dont print\n",
    "model.fit(images,labels,batch_size=64,epochs=50,verbose=1,validation_split=0.2,callbacks=[checkpoint])\n",
    "model.save(\"cnn.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model performance\n",
    "cnnValLoss = cnn.history.history['val_loss']\n",
    "cnnValAcc = cnn.history.history['val_acc']\n",
    "cnnAcc = cnn.history.history['acc']\n",
    "cnnLoss = cnn.history.history['loss']\n",
    "epoch = cnn.history.epoch\n",
    "plt.plot(epoch,cnnAcc,'b',label = 'train_acc')\n",
    "plt.plot(epoch,cnnValAcc,'bo',label = 'val_acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('CNN with 3 Conv Layers')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epoch,cnnLoss,'r',label = 'train_loss')\n",
    "plt.plot(epoch,cnnValLoss,'ro',label = 'val_loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.title('CNN with 3 Conv Layers')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the saved optimal weights as the final model\n",
    "cnn.load_weights('best_weights.hdf5')\n",
    "cnn.save('shapes_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Draw confusion_matrix\n",
    "Y_pred = np.array([np.argmax(i) for i in model.predict(X_test)])\n",
    "Y = np.array([j for i in Y_test for j in range(len(i)) if i[j] != 0.0])\n",
    "confusion = tf.confusion_matrix(labels=Y, predictions=Y_pred, num_classes=26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(Y, Y_pred, labels=[i for i in range(26)]) \n",
    "letters = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "plot_confusion_matrix(cm = confusion, normalize=False, target_names=[i for i in letters], title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss = model.history.history['val_loss']\n",
    "val_acc = model.history.history['val_acc']\n",
    "acc = model.history.history['acc']\n",
    "loss = model.history.history['loss']\n",
    "epoch = model.history.epoch\n",
    "plt.plot(epoch,acc, label = 'train_acc')\n",
    "plt.plot(epoch, loss, label = 'train_loss')\n",
    "plt.plot(epoch, val_acc, label = 'val_acc')\n",
    "plt.plot(epoch, val_loss, label = 'val_loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('acc-loss')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part, we use csv file to train using AlexNet\n",
    "\n",
    "The basic architecture of AlexNet build by TensorFlow is following this tutorial: \n",
    "https://www.digitalocean.com/community/tutorials/how-to-build-a-neural-network-to-recognize-handwritten-digits-with-tensorflow\n",
    "The code is NOT exactly the same as the tutorial.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data from csv file\n",
    "alphabet = pd.read_csv('../EMNIST_28_28_v2.csv')\n",
    "#shuffle the data set\n",
    "alphabet=alphabet.sample(frac=1)\n",
    "#split features and labels\n",
    "images=alphabet.iloc[:,1:].values\n",
    "raw_labels=alphabet.iloc[:,0].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=one_hot(raw_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just set validation to be 2000 we have limited hardware resource\n",
    "validation=2000\n",
    "\n",
    "train_images = images[validation:]\n",
    "train_labels = labels[validation:]\n",
    "\n",
    "validation_images = images[:validation]\n",
    "validation_labels = labels[:validation]\n",
    "\n",
    "n_batch = train_images.shape[0] / 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following code is a modified code from reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tf.placeholder(tf.float32,[None,784])\n",
    "y=tf.placeholder(tf.float32,[None,26])\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def weight and bias for convolutional layer and pooling layer\n",
    "def weight_variable(shape):\n",
    "    return tf.Variable(tf.random_normal(shape))\n",
    "\n",
    "\n",
    "def bias_variable(shape):\n",
    "    return tf.Variable(tf.random_normal(shape))\n",
    "\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_image = tf.reshape(x, [-1, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The parameter us following github code as reference\n",
    "#https://github.com/wwzzyyzzrr/DaChuang/blob/97e07590453a9d6fb3a644ce6abc4a99e2c2d015/Recognition/prediction.py\n",
    "\n",
    "#Layer-1\n",
    "W_conv1 = weight_variable([11, 11, 1, 64])\n",
    "b_conv1 = bias_variable([64])\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "#Layer-2\n",
    "W_conv2 = weight_variable([5, 5, 64,192])\n",
    "b_conv2 = bias_variable([192])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "#Layer-3\n",
    "W_conv3 = weight_variable([3, 3, 192,384])\n",
    "b_conv3 = bias_variable([384])\n",
    "h_conv3 = tf.nn.relu(conv2d(h_pool2, W_conv3) + b_conv3)\n",
    "\n",
    "#Layer-4\n",
    "W_conv4 = weight_variable([3, 3, 384,256])\n",
    "b_conv4 = bias_variable([256])\n",
    "h_conv4 = tf.nn.relu(conv2d(h_conv3, W_conv4) + b_conv4)\n",
    "\n",
    "#Layer-5\n",
    "W_conv5 = weight_variable([3, 3, 256,256])\n",
    "b_conv5 = bias_variable([256])\n",
    "h_conv5 = tf.nn.relu(conv2d(h_conv4, W_conv5) + b_conv5)\n",
    "h_pool5 = max_pool_2x2(h_conv5)\n",
    "\n",
    "#Fully Connected Layer \n",
    "dense1 = tf.reshape(h_pool5, [-1, weight_variable([4*4*256, 1024]).get_shape().as_list()[0]])\n",
    "dense1 = tf.nn.relu(tf.matmul(dense1, weight_variable([4*4*256, 1024])) + bias_variable([1024]),name='fc1')\n",
    "dense2 = tf.nn.relu(tf.matmul(dense1, weight_variable([1024, 1024])) + bias_variable([1024]),name='fc2')\n",
    "\n",
    "y_conv = tf.matmul(dense2,  weight_variable([1024, 26])) + bias_variable([26])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the mean of cross entropy as loss function\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=y_conv))\n",
    "#Use gradient descent to optimize the parameters and the rate is set to 0.1\n",
    "train_step = tf.train.AdadeltaOptimizer(learning_rate=0.1).minimize(loss)\n",
    "\n",
    "#set the accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_conv, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "#set the name of saved model\n",
    "global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "#Initialize\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_loss = np.zeros([50])\n",
    "accuracy_n = np.zeros([50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "     sess.run(init)\n",
    "\n",
    "    for epoch in range(1,51):\n",
    "         for batch in range(int(n_batch)):\n",
    "            batch_x = train_images[batch*100:(batch+1)*100]\n",
    "            batch_y = train_labels[batch*100:(batch+1)*100]\n",
    "\n",
    "            sess.run(train_step,feed_dict = {x:batch_x,y:batch_y,keep_prob:0.5})\n",
    "\n",
    "        accuracy_n[epoch-1] = sess.run(accuracy,feed_dict={x:validation_images, y:validation_labels,keep_prob:1.0})\n",
    "        the_loss[epoch-1] = sess.run(loss,feed_dict={x:validation_images, y:validation_labels,keep_prob:1.0})\n",
    "        the_loss[epoch-1]/=10000000000000\n",
    "        print(\"Round:\" + str(epoch) +\",accuracy:\"+str(accuracy_n[epoch-1])+\",loss:\"+str(the_loss[epoch-1]))\n",
    "\n",
    "        global_step.assign(epoch).eval()\n",
    "        saver.save(sess,\"../alexnet.ckpt\",global_step = global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot loss and accuracy\n",
    "fig, ax1 = plt.subplots()\n",
    "ax2 = ax1.twinx()\n",
    "lns1 = ax1.plot(np.arange(50), the_loss, label=\"Loss\")\n",
    "lns2 = ax2.plot(np.arange(50), accuracy_n, 'r', label=\"Accuracy\")\n",
    "ax1.set_xlabel('iteration')\n",
    "ax1.set_ylabel('training loss')\n",
    "ax2.set_ylabel('training accuracy')\n",
    "lns = lns1 + lns2\n",
    "labels = [\"Loss\", \"Accuracy\"]\n",
    "plt.legend(lns, labels, loc=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    saver.restore(sess, \"../alexnet.ckpt-50\")\n",
    "\n",
    "    test_x = validation_images\n",
    "    conv_y_preditct = y_conv.eval(feed_dict={x: test_x, keep_prob: 1.0})\n",
    "    test_pred = np.argmax(conv_y_preditct, axis=1)\n",
    "    print(test_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same,plot confusion matrix\n",
    "letters = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "y = np.array([j for i in validation_labels for j in range(len(i)) if i[j] != 0.0])\n",
    "confusion = confusion_matrix(y,  test_pred, labels=[i for i in range(26)]) \n",
    "plot_confusion_matrix(cm=confusion,normalize=False,target_names=[i for i in letters])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
